# 图像特征
应用场景在于提取图像中特殊的信息，对物体的识别一般都是对特征的识别

## 形状特征
常用的特征类型:
- 颜色
- 纹理
- 空间

颜色特征:
- 颜色直方图
- 颜色空间
- 颜色分布

纹理特征：
- 一种全局特征
- 描述的是表面特征
- 无法反应舞台的本质属性


形状特征：
- 一类是轮廓特征
- 一类是区域特征

空间关系特征：
- 描述的多个目标空间关系或者相对方向关系
- 包括连接，邻接，重叠、交叠包含和独立等等

## HOG特征提取
histogram of Oriented Gradient, HOG

- 是一种cv和图像中用来进行物体检测的特征描述子
- 计算和统计图像局部区域的梯度方向直方图来构成特征
- HOG and SVM分类器，在行人检测中效果很好
- 主要思想：在思想是一幅图像，目标的形状能够被梯度变化很好的描述

内部实现:
- 灰度化
- Gamma矫正，对颜色空间的标准化
- 计算每个像素的梯度，包括大小和方向
- 将图像划分诚小cells
- 统计每个cell的梯度直方图(不同梯度的的个数),得到cell的描述子
- 将几个cell组合诚block，得到block的描述子
- 将图像img的所有block的HOG特征descriptor串联起来就得到了HOG特征
- 该特征向量就是用来目标检测或者分类的特征

```
pass
```
  
## 角点检测
角点的特征：
- 轮廓的交点
- 同一个场景下，即使视角发生变化，通常具有稳定的特征
- 该点附近区域，像素无论在梯度方向还是幅值都有较大的变化
性能好的角点：
- 检测出图像中真实的角点
- 准确定位性能
- 高重复检测率
- 噪声的鲁棒性
- 较高的计算率
-
## 角点检测:Harris实现过程
1. 计算图像在X和Y方向的梯度
```
$$ 
I_x = \frac{\partial I}{\partial x} =I \otimes \left ( 1,0,1 \right ) ,
I_y = \frac{\partial I}{\partial y} =I \otimes \left ( -1,0,1 \right ) ^T
$$
```
2. 计算图像两个方向梯度的乘积
````
I_x *I_x ,I_x*I_y , I_y*I_y
````
3. 使用高斯函数对三者进行高斯加权生成矩阵M的A,B,C
```
A = g(I_x *I_x)
C = g(I_y*I_y)
B = g(I_x*I_y)
```
4. 计算每个像素的Harris响应值R，并对小于某阈值t的R置为0
5. 在3阶或者5阶邻域内进行非最大值抑制，局部最大值点就是图像的角点

### Harris实现代码
```
在opencv是通过函数cv2.cornerHarris(img,blocksize,ksize-Sobel,K-Harris)实现
其中:
:param img: float 32 img_gary
:param blocksize: 角点考虑的领域大小
:param ksizeSobel: 求导中窗口大小
:param KHarris: 角点检测方策中自由参数，取值范围推荐[0.04-0.06]
```

### SIFT算法
scale-invariant feature fransform,SIFT

尺度不变特征变换算法
SIFT特性:
- 独特性，分辨率高，类似指纹，可以很好匹配
- 多量性，特征多
- 速度快
- 可拓展，能与其他特征向量联合使用
特点:
- 旋转、缩放、平移不变性
- 解决放射变换，投影变换的关键匹配
- 光照影响小
- 目标遮挡小
- 噪声景物影响小

### SIFT实现步骤
1. 在尺度空间极值点检测(特征金字塔)
2. 关键点定位：去除特征点不好的点，保存稳定特征点
3. 关键点方向参数:获取关键点尺度空间的邻域，然后计算该区域的梯度和方向，根据计算结果创建在方向直方图，直方图峰值为主方向参数
4. 关键点描述:每个个关键点用一组向量 (position,scale,direction)将点描述出来，避免其受到光照，视角等影响
5. 关键点匹配:分别对模板图和实时图建立关键点描述符集合,对关键点描述判断两个点是否相同

### SIFT代码实现
```
img = cv2.imread()
gary
sift = cv2.xfeatures2d.SIFT_create()

kp = sift.detect(gary,None)
img = cv2.drawKeypoints(gary,kp,img)
其中:
sift.compute()计算关键点和其描述符
kp,description = sift.compute()
也可以直接寻到关键点并计算
sfit.computeAndCompute()
kp是关键点列表
description是关键点数目*128的numpy数组
```

## 纹理特征
### LBP算法
基本原理:
- 以3阶窗口为例子
- 中心点依次与其他剩余8个点比较灰度值，大于该值为0，小于为0
- 这样就得到了一个8位2进制，可以刚好转化到0-255空间
- 用该值所对应的十进制为该点灰度值
- 遍历整个图像，得到纹理图

### LBP实现代码
```python
# 目前在py中对LBPO的实现不是很好，如下是一个简单的
def LBP(src):
    '''
    :param src:灰度图像
    :return:
    '''
    height = src.shape[0]
    width = src.shape[1]
    dst = src.copy()
    lbp_value = np.zeros((1,8), dtype=np.uint8)
    #print(lbp_value)
    neighbours = np.zeros((1,8), dtype=np.uint8)
    #print(neighbours)
    for x in range(1, width-1):
        for y in range(1, height-1):
            neighbours[0, 0] = src[y - 1, x - 1]
            neighbours[0, 1] = src[y - 1, x]
            neighbours[0, 2] = src[y - 1, x + 1]
            neighbours[0, 3] = src[y, x - 1]
            neighbours[0, 4] = src[y, x + 1]
            neighbours[0, 5] = src[y + 1, x - 1]
            neighbours[0, 6] = src[y + 1, x]
            neighbours[0, 7] = src[y + 1, x + 1]
            center = src[y, x]
            for i in range(8):
                if neighbours[0, i] > center:
                    lbp_value[0, i] = 1
                else:
                    lbp_value[0, i] = 0

            lbp = lbp_value[0, 0] * 1 + lbp_value[0, 1] * 2 + lbp_value[0, 2] * 4 + lbp_value[0, 3] * 8 \
                + lbp_value[0, 4] * 16 + lbp_value[0, 5] * 32 + lbp_value[0, 6] * 64 + lbp_value[0, 7] * 128
            
            #print(lbp)
            dst[y, x] = lbp

    return dst
```

## 模板匹配
对子图和对比图，比对相同点，找出子图所在的位置，在这个过程中需要判定相似程度

cv.matchTemplate(img,templ,method)
其中:
- img 待搜索图像
- templ 模板图/子图 ，需要规模小于等于源图，且数据类型相同
- method 计算匹配程度的方法
  -   有三个方法，需要了解哈
 
 

















